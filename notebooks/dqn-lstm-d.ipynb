{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12f264b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add parent directory to path: enable import from parent dir\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from environment import SmartBrokerEnv\n",
    "from agents.dqn import DQN\n",
    "from networks.lstm_dueling import LSTMDueling\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4141376e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vinay/miniforge3/lib/python3.9/site-packages/pandas/core/frame.py:3641: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n",
      "/Users/vinay/code/git/smart-broker/notebooks/../environment.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.df['rolling_price'] = self.df[self.price_typ].rolling(self.roll_period).sum()\n",
      "/Users/vinay/miniforge3/lib/python3.9/site-packages/pandas/util/_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "norm_cols = ['Volume XRP']\n",
    "cols = ['date'] + ['open', 'high', 'low', 'close', f'Volume XRP']\n",
    "batch_dur = 20\n",
    "env = SmartBrokerEnv(\n",
    "    batch_dur=batch_dur,\n",
    "    df_info={\n",
    "        'start_date': '2021-01-01',\n",
    "        'end_date': '2021-02-01',\n",
    "        'norm_cols': norm_cols,\n",
    "        'cols': cols,\n",
    "    },\n",
    "    portfolio={\n",
    "\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65631b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collecting experience...\n",
      "0..\n",
      "Ep: 10 | L: 3847.866 | R: 0.52 | R.Avg.R: 0.51 | P: 0.03 | R.Avg P: 0.02 | B: 91.81 | R.Avg B: 89.2 | R.N_Units: 46\n",
      "Ep: 20 | L: 18969.079 | R: 0.51 | R.Avg.R: 0.52 | P: -1.18 | R.Avg P: 0.39 | B: 86.63 | R.Avg B: 89.54 | R.N_Units: 46\n",
      "Ep: 30 | L: 17981.421 | R: 0.51 | R.Avg.R: 0.52 | P: -0.38 | R.Avg P: 0.36 | B: 85.49 | R.Avg B: 89.14 | R.N_Units: 48\n",
      "Ep: 40 | L: 7579.437 | R: 0.53 | R.Avg.R: 0.52 | P: 1.82 | R.Avg P: 0.55 | B: 91.96 | R.Avg B: 89.17 | R.N_Units: 48\n",
      "Ep: 50 | L: 377.629 | R: 0.54 | R.Avg.R: 0.53 | P: 3.5 | R.Avg P: 1.49 | B: 46.06 | R.Avg B: 79.67 | R.N_Units: 94\n",
      "Ep: 60 | L: 424.434 | R: 0.54 | R.Avg.R: 0.54 | P: 3.78 | R.Avg P: 2.44 | B: 52.86 | R.Avg B: 57.29 | R.N_Units: 195\n",
      "Ep: 70 | L: 386.044 | R: 0.53 | R.Avg.R: 0.53 | P: 2.87 | R.Avg P: 2.66 | B: 61.12 | R.Avg B: 49.83 | R.N_Units: 228\n",
      "Ep: 80 | L: 374.904 | R: 0.52 | R.Avg.R: 0.54 | P: 0.78 | R.Avg P: 2.97 | B: 46.02 | R.Avg B: 53.07 | R.N_Units: 216\n",
      "Ep: 90 | L: 409.161 | R: 0.55 | R.Avg.R: 0.53 | P: 5.06 | R.Avg P: 3.22 | B: 45.16 | R.Avg B: 55.23 | R.N_Units: 208\n",
      "Ep: 100 | L: 19.096 | R: 0.54 | R.Avg.R: 0.54 | P: 3.56 | R.Avg P: 3.0 | B: 53.44 | R.Avg B: 57.69 | R.N_Units: 196\n",
      "Ep: 110 | L: 327.522 | R: 0.53 | R.Avg.R: 0.53 | P: 1.62 | R.Avg P: 2.88 | B: 46.31 | R.Avg B: 51.44 | R.N_Units: 222\n",
      "Ep: 120 | L: 444.779 | R: 0.55 | R.Avg.R: 0.53 | P: 5.18 | R.Avg P: 2.53 | B: 41.26 | R.Avg B: 50.26 | R.N_Units: 226\n",
      "Ep: 130 | L: 331.104 | R: 0.53 | R.Avg.R: 0.53 | P: 2.78 | R.Avg P: 2.66 | B: 54.52 | R.Avg B: 51.75 | R.N_Units: 220\n",
      "Ep: 140 | L: 482.026 | R: 0.54 | R.Avg.R: 0.54 | P: 3.79 | R.Avg P: 3.19 | B: 51.32 | R.Avg B: 53.83 | R.N_Units: 213\n",
      "Ep: 150 | L: 403.038 | R: 0.54 | R.Avg.R: 0.53 | P: 4.23 | R.Avg P: 3.34 | B: 55.65 | R.Avg B: 54.62 | R.N_Units: 211\n",
      "Ep: 160 | L: 433.319 | R: 0.54 | R.Avg.R: 0.53 | P: 2.58 | R.Avg P: 2.88 | B: 60.58 | R.Avg B: 50.43 | R.N_Units: 227\n",
      "Ep: 170 | L: 256.665 | R: 0.51 | R.Avg.R: 0.53 | P: -0.22 | R.Avg P: 2.25 | B: 51.23 | R.Avg B: 48.22 | R.N_Units: 233\n",
      "Ep: 180 | L: 450.728 | R: 0.53 | R.Avg.R: 0.53 | P: 3.7 | R.Avg P: 2.31 | B: 31.74 | R.Avg B: 46.59 | R.N_Units: 241\n",
      "Ep: 190 | L: 423.038 | R: 0.52 | R.Avg.R: 0.53 | P: 0.41 | R.Avg P: 2.64 | B: 44.56 | R.Avg B: 46.36 | R.N_Units: 244\n",
      "Ep: 200 | L: 18.755 | R: 0.54 | R.Avg.R: 0.53 | P: 3.5 | R.Avg P: 2.62 | B: 45.51 | R.Avg B: 45.63 | R.N_Units: 247\n",
      "Ep: 210 | L: 424.95 | R: 0.55 | R.Avg.R: 0.53 | P: 5.47 | R.Avg P: 2.69 | B: 64.82 | R.Avg B: 45.74 | R.N_Units: 246\n",
      "Ep: 220 | L: 382.734 | R: 0.55 | R.Avg.R: 0.53 | P: 5.3 | R.Avg P: 2.54 | B: 45.81 | R.Avg B: 52.59 | R.N_Units: 216\n",
      "Ep: 230 | L: 458.83 | R: 0.52 | R.Avg.R: 0.53 | P: 0.55 | R.Avg P: 2.35 | B: 50.29 | R.Avg B: 56.09 | R.N_Units: 200\n",
      "Ep: 240 | L: 355.099 | R: 0.52 | R.Avg.R: 0.53 | P: 1.52 | R.Avg P: 2.7 | B: 43.63 | R.Avg B: 50.47 | R.N_Units: 226\n",
      "Ep: 250 | L: 302.975 | R: 0.52 | R.Avg.R: 0.53 | P: 0.82 | R.Avg P: 2.39 | B: 53.59 | R.Avg B: 51.91 | R.N_Units: 218\n",
      "Ep: 260 | L: 429.304 | R: 0.54 | R.Avg.R: 0.54 | P: 3.64 | R.Avg P: 2.34 | B: 54.76 | R.Avg B: 55.51 | R.N_Units: 203\n",
      "Ep: 270 | L: 449.854 | R: 0.55 | R.Avg.R: 0.54 | P: 5.43 | R.Avg P: 3.23 | B: 26.7 | R.Avg B: 51.19 | R.N_Units: 225\n",
      "Ep: 280 | L: 479.588 | R: 0.53 | R.Avg.R: 0.53 | P: 2.65 | R.Avg P: 2.6 | B: 44.29 | R.Avg B: 45.96 | R.N_Units: 245\n",
      "Ep: 290 | L: 466.32 | R: 0.55 | R.Avg.R: 0.54 | P: 4.8 | R.Avg P: 2.87 | B: 51.12 | R.Avg B: 44.33 | R.N_Units: 253\n",
      "Ep: 300 | L: 19.456 | R: 0.54 | R.Avg.R: 0.53 | P: 3.1 | R.Avg P: 3.22 | B: 44.22 | R.Avg B: 45.44 | R.N_Units: 250\n",
      "Ep: 310 | L: 367.541 | R: 0.54 | R.Avg.R: 0.53 | P: 4.11 | R.Avg P: 2.56 | B: 52.08 | R.Avg B: 49.58 | R.N_Units: 229\n",
      "Ep: 320 | L: 379.02 | R: 0.52 | R.Avg.R: 0.53 | P: 1.2 | R.Avg P: 2.46 | B: 55.8 | R.Avg B: 50.67 | R.N_Units: 224\n",
      "Ep: 330 | L: 290.75 | R: 0.56 | R.Avg.R: 0.53 | P: 6.5 | R.Avg P: 2.76 | B: 48.51 | R.Avg B: 49.45 | R.N_Units: 230\n",
      "Ep: 340 | L: 460.442 | R: 0.55 | R.Avg.R: 0.53 | P: 5.56 | R.Avg P: 3.15 | B: 46.63 | R.Avg B: 53.19 | R.N_Units: 216\n",
      "Ep: 350 | L: 390.544 | R: 0.54 | R.Avg.R: 0.54 | P: 3.24 | R.Avg P: 3.24 | B: 54.36 | R.Avg B: 55.39 | R.N_Units: 207\n",
      "Ep: 360 | L: 507.447 | R: 0.52 | R.Avg.R: 0.53 | P: 1.3 | R.Avg P: 2.63 | B: 55.17 | R.Avg B: 54.92 | R.N_Units: 206\n",
      "Ep: 370 | L: 411.924 | R: 0.52 | R.Avg.R: 0.53 | P: 1.14 | R.Avg P: 2.09 | B: 54.21 | R.Avg B: 52.71 | R.N_Units: 214\n",
      "Ep: 380 | L: 415.952 | R: 0.54 | R.Avg.R: 0.53 | P: 3.98 | R.Avg P: 2.32 | B: 51.47 | R.Avg B: 51.25 | R.N_Units: 221\n",
      "Ep: 390 | L: 388.273 | R: 0.53 | R.Avg.R: 0.54 | P: 2.34 | R.Avg P: 2.87 | B: 45.95 | R.Avg B: 52.43 | R.N_Units: 218\n",
      "Ep: 400 | L: 6.635 | R: 0.53 | R.Avg.R: 0.53 | P: 2.68 | R.Avg P: 2.85 | B: 46.68 | R.Avg B: 55.19 | R.N_Units: 206\n",
      "Ep: 410 | L: 267.949 | R: 0.52 | R.Avg.R: 0.54 | P: 1.44 | R.Avg P: 2.69 | B: 51.64 | R.Avg B: 53.3 | R.N_Units: 214\n",
      "Ep: 420 | L: 421.937 | R: 0.55 | R.Avg.R: 0.54 | P: 4.78 | R.Avg P: 3.21 | B: 63.6 | R.Avg B: 55.57 | R.N_Units: 206\n",
      "Ep: 430 | L: 447.974 | R: 0.56 | R.Avg.R: 0.54 | P: 5.92 | R.Avg P: 3.56 | B: 57.4 | R.Avg B: 61.44 | R.N_Units: 182\n",
      "Ep: 440 | L: 459.714 | R: 0.54 | R.Avg.R: 0.53 | P: 4.17 | R.Avg P: 3.27 | B: 54.48 | R.Avg B: 56.05 | R.N_Units: 204\n",
      "Ep: 450 | L: 407.296 | R: 0.52 | R.Avg.R: 0.53 | P: 1.61 | R.Avg P: 2.71 | B: 43.92 | R.Avg B: 50.71 | R.N_Units: 225\n",
      "Ep: 460 | L: 408.857 | R: 0.54 | R.Avg.R: 0.54 | P: 3.44 | R.Avg P: 3.01 | B: 57.04 | R.Avg B: 49.11 | R.N_Units: 233\n",
      "Ep: 470 | L: 475.419 | R: 0.54 | R.Avg.R: 0.53 | P: 3.91 | R.Avg P: 3.02 | B: 55.51 | R.Avg B: 46.73 | R.N_Units: 243\n",
      "Ep: 480 | L: 424.789 | R: 0.54 | R.Avg.R: 0.53 | P: 2.99 | R.Avg P: 2.7 | B: 68.97 | R.Avg B: 49.59 | R.N_Units: 230\n",
      "Ep: 490 | L: 226.236 | R: 0.53 | R.Avg.R: 0.53 | P: 2.19 | R.Avg P: 2.57 | B: 60.1 | R.Avg B: 54.51 | R.N_Units: 208\n",
      "Ep: 500 | L: 7.598 | R: 0.53 | R.Avg.R: 0.54 | P: 2.19 | R.Avg P: 3.18 | B: 54.0 | R.Avg B: 48.78 | R.N_Units: 235\n",
      "Ep: 510 | L: 295.535 | R: 0.53 | R.Avg.R: 0.54 | P: 2.79 | R.Avg P: 3.72 | B: 55.56 | R.Avg B: 48.83 | R.N_Units: 237\n",
      "Ep: 520 | L: 292.552 | R: 0.56 | R.Avg.R: 0.53 | P: 5.9 | R.Avg P: 3.16 | B: 42.44 | R.Avg B: 54.27 | R.N_Units: 211\n",
      "Ep: 530 | L: 443.814 | R: 0.52 | R.Avg.R: 0.54 | P: 0.38 | R.Avg P: 2.96 | B: 55.91 | R.Avg B: 50.34 | R.N_Units: 228\n",
      "Ep: 540 | L: 464.127 | R: 0.53 | R.Avg.R: 0.53 | P: 2.53 | R.Avg P: 2.61 | B: 50.25 | R.Avg B: 50.81 | R.N_Units: 224\n",
      "Ep: 550 | L: 453.348 | R: 0.54 | R.Avg.R: 0.53 | P: 4.58 | R.Avg P: 2.56 | B: 51.65 | R.Avg B: 52.35 | R.N_Units: 217\n",
      "Ep: 560 | L: 440.284 | R: 0.53 | R.Avg.R: 0.53 | P: 2.18 | R.Avg P: 2.55 | B: 41.04 | R.Avg B: 50.45 | R.N_Units: 225\n",
      "Ep: 570 | L: 372.443 | R: 0.53 | R.Avg.R: 0.53 | P: 2.38 | R.Avg P: 2.61 | B: 50.38 | R.Avg B: 48.94 | R.N_Units: 232\n",
      "Ep: 580 | L: 357.398 | R: 0.54 | R.Avg.R: 0.53 | P: 3.54 | R.Avg P: 2.81 | B: 48.43 | R.Avg B: 48.9 | R.N_Units: 233\n",
      "Ep: 590 | L: 504.221 | R: 0.53 | R.Avg.R: 0.53 | P: 2.21 | R.Avg P: 2.53 | B: 52.55 | R.Avg B: 51.7 | R.N_Units: 220\n",
      "Ep: 600 | L: 8.558 | R: 0.54 | R.Avg.R: 0.54 | P: 3.91 | R.Avg P: 3.49 | B: 42.89 | R.Avg B: 51.43 | R.N_Units: 225\n",
      "Ep: 610 | L: 467.031 | R: 0.54 | R.Avg.R: 0.54 | P: 3.5 | R.Avg P: 3.84 | B: 52.63 | R.Avg B: 51.07 | R.N_Units: 228\n",
      "Ep: 620 | L: 476.77 | R: 0.53 | R.Avg.R: 0.53 | P: 2.11 | R.Avg P: 3.05 | B: 53.26 | R.Avg B: 48.54 | R.N_Units: 236\n",
      "Ep: 630 | L: 370.846 | R: 0.54 | R.Avg.R: 0.53 | P: 4.21 | R.Avg P: 2.8 | B: 49.48 | R.Avg B: 48.48 | R.N_Units: 235\n",
      "Ep: 640 | L: 436.113 | R: 0.54 | R.Avg.R: 0.53 | P: 3.94 | R.Avg P: 2.8 | B: 57.83 | R.Avg B: 52.2 | R.N_Units: 219\n",
      "Ep: 650 | L: 443.416 | R: 0.55 | R.Avg.R: 0.53 | P: 4.84 | R.Avg P: 2.73 | B: 41.22 | R.Avg B: 53.13 | R.N_Units: 214\n",
      "Ep: 660 | L: 377.312 | R: 0.52 | R.Avg.R: 0.53 | P: 1.21 | R.Avg P: 2.28 | B: 66.51 | R.Avg B: 54.06 | R.N_Units: 209\n",
      "Ep: 670 | L: 344.743 | R: 0.54 | R.Avg.R: 0.53 | P: 4.23 | R.Avg P: 2.49 | B: 40.18 | R.Avg B: 53.15 | R.N_Units: 213\n",
      "Ep: 680 | L: 403.904 | R: 0.54 | R.Avg.R: 0.53 | P: 3.14 | R.Avg P: 3.08 | B: 45.88 | R.Avg B: 51.44 | R.N_Units: 223\n",
      "Ep: 690 | L: 392.003 | R: 0.5 | R.Avg.R: 0.53 | P: -1.31 | R.Avg P: 2.8 | B: 50.33 | R.Avg B: 49.87 | R.N_Units: 229\n",
      "Ep: 700 | L: 7.34 | R: 0.52 | R.Avg.R: 0.53 | P: 0.44 | R.Avg P: 2.68 | B: 59.66 | R.Avg B: 51.1 | R.N_Units: 223\n",
      "Ep: 710 | L: 471.371 | R: 0.54 | R.Avg.R: 0.53 | P: 3.39 | R.Avg P: 2.86 | B: 51.87 | R.Avg B: 54.61 | R.N_Units: 209\n",
      "Ep: 720 | L: 513.031 | R: 0.56 | R.Avg.R: 0.53 | P: 6.37 | R.Avg P: 3.09 | B: 42.04 | R.Avg B: 52.41 | R.N_Units: 219\n",
      "Ep: 730 | L: 505.174 | R: 0.53 | R.Avg.R: 0.54 | P: 2.34 | R.Avg P: 3.45 | B: 55.36 | R.Avg B: 51.41 | R.N_Units: 225\n",
      "Ep: 740 | L: 591.719 | R: 0.53 | R.Avg.R: 0.53 | P: 1.3 | R.Avg P: 3.21 | B: 58.59 | R.Avg B: 54.99 | R.N_Units: 209\n",
      "Ep: 750 | L: 508.668 | R: 0.55 | R.Avg.R: 0.53 | P: 4.85 | R.Avg P: 3.02 | B: 50.79 | R.Avg B: 56.58 | R.N_Units: 201\n",
      "Ep: 760 | L: 314.53 | R: 0.51 | R.Avg.R: 0.53 | P: 0.05 | R.Avg P: 2.51 | B: 42.07 | R.Avg B: 52.08 | R.N_Units: 218\n",
      "Ep: 770 | L: 484.875 | R: 0.53 | R.Avg.R: 0.53 | P: 2.05 | R.Avg P: 2.52 | B: 47.34 | R.Avg B: 49.6 | R.N_Units: 229\n",
      "Ep: 780 | L: 504.119 | R: 0.53 | R.Avg.R: 0.53 | P: 1.75 | R.Avg P: 3.11 | B: 63.95 | R.Avg B: 50.59 | R.N_Units: 227\n",
      "Ep: 790 | L: 414.996 | R: 0.56 | R.Avg.R: 0.54 | P: 6.64 | R.Avg P: 3.26 | B: 50.78 | R.Avg B: 49.77 | R.N_Units: 232"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/78/_bz_v2_103ld252mxn9ml9c00000gn/T/ipykernel_23364/1125330979.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m )\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mdqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/code/git/smart-broker/notebooks/../agents/dqn.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, ep)\u001b[0m\n\u001b[1;32m    281\u001b[0m                     \u001b[0mtransitions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplay_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mtimestep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_freq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m                         \u001b[0mep_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransitions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_no\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_sync_freq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/git/smart-broker/notebooks/../agents/dqn.py\u001b[0m in \u001b[0;36m_train_one_batch\u001b[0;34m(self, transitions, epsilon)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'lstm'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m             Q_values, self.train_hdn_st = self.policy_net(\n\u001b[0m\u001b[1;32m    195\u001b[0m                 \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_hdn_st\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/git/smart-broker/notebooks/../networks/lstm_dueling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, prev_state)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[1;32m    692\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    693\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "target_net = LSTMDueling(\n",
    "    input_dim=batch_dur*3+3,\n",
    "    output_dim=3,\n",
    ")\n",
    "\n",
    "policy_net = LSTMDueling(\n",
    "    input_dim=batch_dur*3+3,\n",
    "    output_dim=3,\n",
    ")\n",
    "\n",
    "dqn = DQN(\n",
    "    env=env,\n",
    "    env_type='vector',\n",
    "    n_actions=3,\n",
    "    log_freq=10,\n",
    "    train_freq=3,\n",
    "    batch_size=batch_size,\n",
    "    w_sync_freq=1,\n",
    "    memory_size=500,\n",
    "    gamma=0.9995,\n",
    "    step_size=0.01,\n",
    "    episodes=500,\n",
    "    target_net=target_net,\n",
    "    policy_net=policy_net,\n",
    "    loss_func=nn.SmoothL1Loss(),\n",
    "    optimizer=torch.optim.Adam(policy_net.parameters(), lr=0.00008),\n",
    "    load_pretrained=False,\n",
    "    save_pretrained=False,\n",
    "    model_path='../models/dqn_lstm',\n",
    "    network_type='lstm',\n",
    ")\n",
    "\n",
    "dqn.run(5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2138d708-a6a0-4322-a148-016753dd168e",
   "metadata": {},
   "source": [
    "### Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541e476d-f376-444f-97f3-fb641a990238",
   "metadata": {},
   "source": [
    "### Traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae43c7d4-7e90-4c0a-ab33-4d1e16c06c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 2, figsize=(16, 12))\n",
    "r_avg_rewards = []\n",
    "r_avg_profits = []\n",
    "r_avg_bal = []\n",
    "r_avg_units_held = []\n",
    "r_avg_loss = []\n",
    "r_avg_net_worth = []\n",
    "count = 0\n",
    "\n",
    "for _, log in dqn.logs.items():\n",
    "    r_avg_rewards.append(log['r_avg_reward'])\n",
    "    r_avg_profits.append(log['r_avg_profit'])\n",
    "    r_avg_bal.append(log['r_avg_bal'])\n",
    "    r_avg_units_held.append(log['r_avg_units_held'])\n",
    "    r_avg_loss.append(log['r_avg_loss'])\n",
    "    r_avg_net_worth.append(log['r_avg_net_worth'])\n",
    "    count += 1\n",
    "\n",
    "ax[0][0].plot(range(count), r_avg_loss)\n",
    "ax[0][0].set_title('Rolling avg loss per episode')\n",
    "\n",
    "ax[0][1].plot(range(count), r_avg_rewards)\n",
    "ax[0][1].set_title('Rolling avg reward per episode')\n",
    "\n",
    "ax[1][0].plot(range(count), r_avg_profits)\n",
    "ax[1][0].set_title('Rolling avg profit per episode')\n",
    "\n",
    "ax[1][1].plot(range(count), r_avg_units_held)\n",
    "ax[1][1].set_title('Rolling avg units held per episode')\n",
    "\n",
    "ax[2][0].plot(range(count), r_avg_net_worth)\n",
    "ax[2][0].set_title('Rolling avg net worth per episode')\n",
    "\n",
    "ax[2][1].plot(range(count), r_avg_bal)\n",
    "ax[2][1].set_title('Rolling avg balance per episode')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
